{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# José Ligorría\n",
    "## Deployment modelos predicción sobrevivencia de pasajeros en el Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def ClasificadorBinario(pred_x,pendientes,interceptos,scale,mean,sd):\n",
    "    if scale:\n",
    "        pred_x = (pred_x-mean.astype(np.float32))/sd.astype(np.float32)\n",
    "        pred_f = tf.argmax(tf.add(tf.tensordot(pred_x, pendientes,axes = [[1], [0]]), interceptos),1)\n",
    "    else:\n",
    "        pred_f = tf.argmax(tf.add(tf.tensordot(pred_x.astype(np.float32), pendientes,axes = [[1], [0]]), interceptos),1)\n",
    "    with tf.Session() as sess: \n",
    "        pred_f_val = pred_f.eval()\n",
    "    return pred_f_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jose-\\Anaconda3\\envs\\Clases_tensorflow_env2\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Enabled compatitility to tf1.x\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.\"):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.compat.v1.disable_v2_behavior()\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"./Files/\"  + 'Diccionario_Variables' + '.pkl'\n",
    "\n",
    "diccionarioVariables =  joblib.load(input_dir)\n",
    "\n",
    "Best_Dec = glob.glob('./Objects/Best*Dec*.pkl')\n",
    "best_model_dt =  joblib.load(Best_Dec[0])\n",
    "Best_SVM = glob.glob('./Objects/Best*SV*.pkl')\n",
    "best_model_sv =  joblib.load(Best_SVM[0])\n",
    "Best_Nne = glob.glob('./Objects/Best*Nn*.pkl')\n",
    "best_model_nn =  joblib.load(Best_Nne[0])\n",
    "Best_Reg = glob.glob('./Objects/Best*Reg*.pkl')\n",
    "best_model_lr =  joblib.load(Best_Reg[0])\n",
    "\n",
    "Best_Dec_split = Best_Dec[0].split('_')\n",
    "vars_necesitadas_Dec = [x for x in Best_Dec_split if 'var' in x]\n",
    "Best_SVM_split = Best_SVM[0].split('_')\n",
    "vars_necesitadas_SVM = [x for x in Best_SVM_split if 'var' in x]\n",
    "Best_Nne_split = Best_Nne[0].split('_')\n",
    "vars_necesitadas_Nne = [x for x in Best_Nne_split if 'var' in x]\n",
    "Best_Reg_split = Best_Reg[0].split('_')\n",
    "vars_necesitadas_Reg = [x for x in Best_Reg_split if 'var' in x]\n",
    "vars_necesarias = list(set(vars_necesitadas_Dec) | set(vars_necesitadas_SVM) | set(vars_necesitadas_Nne) | set(vars_necesitadas_Reg))\n",
    "variables_necesarias = [diccionarioVariables[x] for x in vars_necesarias]\n",
    "#print('Las variables necesarias para generar una prediccion son:', string_variables)\n",
    "\n",
    "def Prediccion(X):\n",
    "    arr_X = X.reshape((1,-1))\n",
    "    pred_ct_test = best_model_dt.predict(arr_X)\n",
    "    pred_sv_test = best_model_sv.predict(arr_X)\n",
    "    pred_rl_test = ClasificadorBinario(arr_X,best_model_lr[0],best_model_lr[1],best_model_lr[2],best_model_lr[3],best_model_lr[4])\n",
    "    pred_nn_test = best_model_nn.predict(arr_X)\n",
    "    pred_em_test = pred_ct_test + pred_sv_test + pred_rl_test + pred_nn_test\n",
    "    pred_em_test[pred_em_test<=2]=0\n",
    "    pred_em_test[pred_em_test>=2]=1\n",
    "    return int(pred_em_test)\n",
    "\n",
    "def EvalPrediccion(X):\n",
    "    try:\n",
    "        df_X = pd.DataFrame(data=X, index=[0])\n",
    "        variables_en_X = list(df_X.columns)\n",
    "        print(variables_en_X)\n",
    "        if len(variables_en_X) == len(vars_necesarias):\n",
    "            set_difference = set(variables_necesarias) - set(variables_en_X)\n",
    "            #print(set_difference)\n",
    "            if set_difference == []:\n",
    "                #print('Probable')\n",
    "                return Prediccion(df_X)\n",
    "            else:\n",
    "                print('Corregir el nombre de las variables y probar de nuevo')\n",
    "        else:\n",
    "            print('Corregir la cantidad de variables y probar de nuevo')\n",
    "    except:\n",
    "        arr_X = np.array(X,dtype = np.float32)\n",
    "        if len(arr_X) == len(vars_necesarias):\n",
    "            #print('Probable')\n",
    "            return Prediccion(arr_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jose-\\Anaconda3\\envs\\Clases_tensorflow_env2\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:178: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  f\"evaluating in Python space because the {repr(op_str)} \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediccion:  1  real: [1.]\n",
      "Prediccion:  0  real: [1.]\n",
      "Prediccion:  1  real: [0.]\n",
      "Prediccion:  1  real: [1.]\n",
      "Prediccion:  0  real: [0.]\n",
      "Prediccion:  0  real: [1.]\n",
      "Prediccion:  1  real: [1.]\n",
      "Prediccion:  0  real: [0.]\n",
      "Prediccion:  0  real: [1.]\n",
      "Prediccion:  0  real: [0.]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv ('data_titanic_proyecto.csv')\n",
    "dataset = df[['SibSp','Parch','Fare','Embarked','passenger_class','passenger_sex','passenger_survived']]\n",
    "reg_out = [False]*len(dataset)\n",
    "for f in ['SibSp', 'Parch','Fare','Embarked','passenger_class','passenger_sex']:\n",
    "    piv_f = dataset[f]\n",
    "    #print(f,len(Counter(piv_f)),len(piv_f[piv_f.isnull()]))\n",
    "    reg_out += piv_f.isnull()\n",
    "dataset = dataset[-reg_out]\n",
    "dataset = dataset.reset_index()\n",
    "for f in ['Embarked','passenger_class','passenger_sex']:\n",
    "    labels = dataset[f]\n",
    "    distinct_labels = list(set(labels))\n",
    "    labels_num = np.zeros_like(labels)\n",
    "    contador = 0\n",
    "    total = 0\n",
    "    total_ant = 0\n",
    "    cantidad = 0\n",
    "    for i in distinct_labels:\n",
    "        contador += 1\n",
    "        piv1 = labels == i\n",
    "        labels_num[piv1] = contador\n",
    "        total = sum(labels_num)\n",
    "        cantidad += (total-total_ant)/contador\n",
    "        total_ant = total\n",
    "    #print(sum(labels_num),cantidad)\n",
    "    labels_num -= 1\n",
    "    labels_num = labels_num.astype(int)\n",
    "    labels_num_eye = np.eye(len(set(labels_num)))[labels_num]\n",
    "    labels_num_eye =  pd.DataFrame(data=labels_num_eye,columns=[f +'_' + s for s in distinct_labels]  )\n",
    "    len(labels_num_eye)\n",
    "    dataset = dataset.join(labels_num_eye)\n",
    "    dataset.pop(f)\n",
    "labels = dataset['passenger_survived']\n",
    "labels_num = np.zeros_like(labels)\n",
    "labels_num[labels =='Y'] = 1\n",
    "dataset['passenger_survived'] = labels_num\n",
    "dataset = dataset[['SibSp','Parch','Fare','Embarked_S','Embarked_Q','Embarked_C','passenger_class_Lower',\n",
    "                  'passenger_class_Middle','passenger_class_Upper','passenger_sex_M','passenger_sex_F',\n",
    "                  'passenger_survived']]\n",
    "dataset = dataset.sample(n=10)\n",
    "X_test = np.array(dataset[['SibSp','Parch','Fare','Embarked_S','Embarked_Q','Embarked_C','passenger_class_Lower',\n",
    "                      'passenger_class_Middle','passenger_class_Upper','passenger_sex_M','passenger_sex_F']],dtype = np.float32)\n",
    "y_test = np.array(dataset[['passenger_survived']],dtype = np.float32)\n",
    "for i in range(len(dataset)):\n",
    "    dataset_piv = X_test[i]\n",
    "    #print(i)\n",
    "    print('Prediccion: ',EvalPrediccion(dataset_piv),' real:', y_test[i])\n",
    "#len(dataset)\n",
    "#pd.DataFrame(data=dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
